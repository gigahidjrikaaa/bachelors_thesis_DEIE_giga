\chapter{Literature Review and Theoretical Background}

% Bab ini mengulas fondasi konseptual dan empiris yang melandasi penelitian mengenai platform terintegrasi berbasis AI, gamifikasi, dan blockchain untuk keterlibatan dan kesejahteraan mahasiswa. Bagian pertama menyajikan tinjauan pustaka terhadap karya-karya terdahulu yang relevan, mengidentifikasi kontribusi serta keterbatasan mereka, dan memposisikan penelitian ini dalam lanskap keilmuan saat ini. Bagian kedua memaparkan dasar-dasar teori mengenai teknologi inti yang digunakan (AI Konversasional Hibrida, Gamifikasi, Blockchain) serta konsep keterlibatan pengguna dan kesejahteraan mahasiswa dalam konteks digital. Terakhir, bab ini menganalisis secara komparatif pendekatan-pendekatan yang ada dan justifikasi pemilihan metode untuk penelitian ini.

This chapter provides the theoretical foundations and academic context for the research. The first section, Theoretical Background, explains the core concepts and technologies that constitute the proposed framework. The second section, Literature Review, surveys existing work in related fields to identify the research gap that this thesis aims to address.

\section{Theoretical Background}
\label{sec:theoretical_background}

This section describes the foundational principles and technologies upon which the agentic AI framework is built, including Agentic AI, Large Language Models (LLMs), LLM orchestration, and workflow automation platforms.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SubSection: Agentic AI, Multi-Agent Systems, and LLMs
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Agentic AI and Multi-Agent Systems (MAS)}
\label{subsec:agentic_ai}

The paradigm of Artificial Intelligence (AI) has evolved significantly from systems that perform singular, reactive tasks to those that exhibit autonomous, proactive, and social behaviors. A cornerstone of this evolution is the concept of an \textbf{intelligent agent}. An agent is not merely a program; it is a persistent computational entity with a degree of autonomy, situated within an environment, which it can both perceive and upon which it can act to achieve a set of goals or design objectives \cite{FIND_CITATION_PLEASE}. The defining characteristic of an agent is its \textbf{autonomy}—its capacity to operate independently, making decisions and initiating actions without direct, constant human intervention. This is distinct from traditional objects, which are defined by their methods and attributes but do not exhibit control over their own behavior \cite{FIND_CITATION_PLEASE}.

To operationalize this concept, this thesis formally introduces a framework built upon three distinct, specialized intelligent agents. Each agent is designed to address a specific challenge outlined in Chapter 1, and together they form the core of the proposed proactive support system. These agents are:
\begin{itemize}
    \item The \textbf{Analytics Agent}, responsible for data-driven trend identification.
    \item The \textbf{Intervention Agent}, responsible for automating proactive outreach.
    \item The \textbf{Triage Agent}, responsible for real-time user support and resource routing.
\end{itemize}
The theoretical underpinnings of these agents' architecture and behavior are drawn from established models of rational agency and multi-agent systems, as detailed below.

Fundamentally, an agent's operation is defined by a continuous cycle of perception, reasoning (or deliberation), and action. It perceives its environment through virtual \textbf{sensors} (e.g., data feeds, API calls, database queries) and influences that environment through its \textbf{actuators} (e.g., sending emails, generating reports, invoking other services) \cite{FIND_CITATION_PLEASE}. A prominent and highly relevant architecture for designing such goal-oriented agents is the \textbf{Belief-Desire-Intention (BDI)} model \cite{FIND_CITATION_PLEASE}. This model provides a framework for rational agency that mirrors human practical reasoning:
\begin{itemize}
    \item \textbf{Beliefs:} This represents the informational state of the agent—its knowledge about the environment, which may be incomplete or incorrect. For the \textbf{Analytics Agent}, beliefs correspond to the current understanding of student well-being trends derived from anonymized data.
    \item \textbf{Desires:} These are the motivational states of the agent, representing the objectives or goals it is designed to achieve. Desires can be seen as the potential tasks the agent could undertake, such as the \textbf{Intervention Agent's} overarching goal to "automate proactive outreach."
    \item \textbf{Intentions:} This represents the agent's commitment to a specific plan or course of action. An intention is a desire that the agent has chosen to actively pursue. For instance, the \textbf{Triage Agent}, upon identifying a high-severity conversation, forms an intention to immediately route the user to emergency resources.
\end{itemize}
The BDI framework allows for the design of agents that are not merely reactive but are proactive and deliberative, capable of reasoning about how to best achieve their goals given their current beliefs about the world \cite{FIND_CITATION_PLEASE}.

When multiple agents, each with its own goals and capabilities, co-exist and interact within a shared environment, they form a \textbf{Multi-Agent System (MAS)}. An MAS is a system in which the overall intelligent behavior and functionality are a product of the collective, emergent dynamics of its constituent agents \cite{FIND_CITATION_PLEASE}. The power of an MAS lies in its ability to solve problems that would be difficult or impossible for a monolithic system or a single agent to handle. This is achieved through social interaction, primarily:
\begin{itemize}
    \item \textbf{Coordination and Cooperation:} Agents must coordinate their actions to avoid interference and cooperate to achieve common goals. In this thesis, the \textbf{Analytics}, \textbf{Intervention}, and \textbf{Triage} agents must cooperate: the Analytics Agent provides the data-driven insights (beliefs) that the Intervention Agent uses to form its outreach plans (intentions), while the Triage Agent handles immediate, real-time needs that may fall outside the other agents' scopes.
    \item \textbf{Negotiation:} When agents have conflicting goals or must compete for limited resources, they must be able to negotiate to find a mutually acceptable compromise \cite{FIND_CITATION_PLEASE}.
    \item \textbf{Communication:} Effective interaction requires a shared Agent Communication Language (ACL), such as FIPA-ACL or KQML, which defines the syntax and semantics for messages, allowing agents to perform actions like requesting information, making proposals, and accepting or rejecting tasks \cite{FIND_CITATION_PLEASE}.
\end{itemize}
Therefore, this thesis leverages the MAS paradigm by designing a framework composed of three specialized, collaborative agents. Their individual, goal-directed behaviors, orchestrated within a hybrid architecture, work in concert to achieve the overarching systemic objective: transforming institutional mental health support from a reactive model to a proactive, data-driven ecosystem.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SubSection: Foundational Principles of the Framework
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Foundational Principles of the Framework}
\label{subsec:foundational_principles}

Beyond the technical architecture, the proposed framework is grounded in several key strategic and ethical principles that justify its design and purpose. These concepts from service design, management science, and data ethics provide the theoretical motivation for shifting how institutional support is delivered.

\subsubsection{Proactive vs. Reactive Support Models}
The traditional approach to institutional support, particularly in mental health, is predominantly \textbf{reactive}. This model, common in service design, operates on a "break-fix" basis, where the service delivery is initiated only after a user (in this case, a student) self-identifies a problem and actively seeks a solution \cite{FIND_CITATION_PLEASE}. This places the onus of initiation entirely on the individual, creating significant barriers to access such as stigma, lack of awareness, or the inability to act during a crisis. In contrast, a \textbf{proactive support model} aims to anticipate needs and intervene before a problem escalates. Drawing from principles in preventative healthcare and proactive customer relationship management, this model uses data to identify patterns and risk factors, enabling the institution to offer timely, relevant support to at-risk cohorts \cite{FIND_CITATION_PLEASE}. This thesis is an explicit attempt to architect a system that facilitates this strategic shift from a reactive to a proactive support paradigm.

\subsubsection{Data-Driven Decision-Making in Higher Education}
The concept of \textbf{Data-Driven Decision-Making (DDDM)} posits that strategic decisions should be based on objective data analysis and interpretation rather than solely on intuition or tradition \cite{FIND_CITATION_PLEASE}. In higher education, this has manifested as the field of learning analytics, where student data is used to improve learning outcomes and retention. This framework extends that principle to student well-being. The \textbf{Analytics Agent} is the core enabler of DDDM for the university's support services. By autonomously processing anonymized interaction data to identify trends, sentiment shifts, and emerging topics of concern, it provides administrators with actionable, empirical evidence. This allows the institution to move beyond anecdotal evidence and allocate resources—such as workshops, counselors, or targeted information campaigns—to where they are most needed, thereby optimizing the efficiency and impact of its support ecosystem.

\subsubsection{Privacy by Design (PbD)}
Given the highly sensitive nature of mental health data, the framework's architecture is guided by the principles of \textbf{Privacy by Design (PbD)}. PbD is an internationally recognized framework, formalized in ISO 31700, which dictates that privacy should be the default, embedded into the design and architecture of systems from the outset rather than being an add-on feature \cite{FIND_CITATION_PLEASE}. Key principles include being proactive not reactive, making privacy the default setting, and providing end-to-end security. The architectural decision to include a dedicated \textbf{Safeguard LLM} is a direct implementation of PbD. Its sole purpose is to proactively identify and redact Personally Identifiable Information (PII) before data is used for analysis, ensuring that privacy is protected by default at the earliest possible stage of the data lifecycle. This demonstrates a commitment to building a system that is not only effective but also fundamentally ethical and secure.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SubSection: Large Language Models (LLMs)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Large Language Models (LLMs)}
\label{subsec:llms}

Large Language Models (LLMs) are a class of deep learning models that have demonstrated remarkable capabilities in understanding and generating human-like text. The architectural foundation for virtually all modern LLMs, including the Gemma and Gemini models used in this research, is the \textbf{Transformer architecture}, first introduced by Vaswani et al. \cite{FIND_CITATION_PLEASE}. The Transformer's key innovation is the \textbf{self-attention mechanism}, which allows the model to dynamically weigh the importance of different words in an input sequence when processing and generating language. This enables the model to capture complex, long-range dependencies and contextual relationships far more effectively than its predecessors, such as Recurrent Neural Networks (RNNs) \cite{FIND_CITATION_PLEASE}.

The core operation of a Transformer-based model involves processing input text through a series of encoding and/or decoding layers. In a generative, decoder-only model like Gemma, the process can be conceptualized as follows:
\begin{enumerate}
    \item \textbf{Tokenization and Embedding:} Input text is first broken down into smaller units called tokens. Each token is then mapped to a high-dimensional vector, or an "embedding," that represents its semantic meaning.
    \item \textbf{Positional Encoding:} Since the self-attention mechanism does not inherently process sequential order, a positional encoding vector is added to each token embedding to provide the model with information about the word's position in the sequence.
    \item \textbf{Self-Attention Layers:} The sequence of embeddings passes through multiple self-attention layers. In each layer, the model calculates attention scores for every token relative to all other tokens in the sequence, effectively learning which parts of the input are most relevant for understanding the context of each specific token.
    \item \textbf{Feed-Forward Networks:} Each attention layer is followed by a feed-forward neural network that applies further transformations to each token's representation.
    \item \textbf{Output Generation:} The model's final output is a probability distribution over its entire vocabulary for the next token in the sequence. The model then typically selects the most likely token (or samples from the distribution) and appends it to the input, repeating the process autoregressively to generate coherent text \cite{FIND_CITATION_PLEASE}.
\end{enumerate}

\begin{figure}[htbp]
  \centering
  % \includegraphics[width=\textwidth]{placeholder_diagram_transformer.png} % Ganti dengan file gambar Anda
  \fbox{\parbox[c][8cm][c]{0.9\textwidth}{\centering \textbf{Placeholder for Diagram: Simplified Transformer Architecture for Generative LLMs} \\ \vspace{1cm} This diagram should illustrate the flow of information: \\ 1. Input Text -> Tokenizer \\ 2. Tokens -> Embedding Layer + Positional Encoding \\ 3. Embedded Tokens -> A stack of 'N' Decoder Blocks \\ 4. Inside a Decoder Block: Multi-Head Self-Attention -> Feed-Forward Network \\ 5. Final Output -> Linear Layer -> Softmax -> Probability of Next Token}}
  \caption{A simplified view of the decoder-only Transformer architecture used in generative LLMs like Gemma. The model processes input embeddings through multiple layers of self-attention and feed-forward networks to predict the next token in a sequence.}
  \label{fig:transformer_architecture}
\end{figure}

This research utilizes a \textbf{hybrid LLM strategy} that leverages two distinct families of models based on this architecture to balance performance, privacy, and capability:
\begin{itemize}
    \item \textbf{Locally-Hosted Open Models (Gemma):} The Gemma models are a family of lightweight, open-weight models developed by Google, built from the same research and technology used to create the Gemini models \cite{FIND_CITATION_PLEASE}. As decoder-only Transformers, they are optimized for generative text tasks. Being "open-weight" means their parameters are publicly available, allowing them to be deployed on institutional hardware. This approach is critical for this project as it guarantees data privacy and security—sensitive student conversations processed by the Triage Agent never leave the university's secure servers. Furthermore, local hosting provides low latency and eliminates per-token API costs, making it a sustainable choice for real-time, high-volume interactions.
    \item \textbf{Cloud-Based API Models (Gemini):} The Gemini models represent Google's state-of-the-art, natively multimodal foundation models, available in various sizes (e.g., Gemini Pro). Unlike models trained solely on text, Gemini was pre-trained from the ground up on multiple data modalities, giving it more sophisticated reasoning capabilities \cite{FIND_CITATION_PLEASE}. In this framework, a powerful model like Gemini Pro is accessed via a secure API for complex, non-sensitive tasks, such as the weekly trend analysis performed by the Analytics Agent. It also serves as a robust fallback mechanism, ensuring service continuity and reliability should the local model encounter issues.
\end{itemize}

\subsubsection{Locally-Hosted Open Models: The Gemma 3 Family}

The selection of Gemma 3 as the locally-hosted model for this framework is predicated on its state-of-the-art capabilities, efficiency, and suitability for advanced, multimodal tasks. Released in March 2025, Gemma 3 represents a significant evolution in Google's open model family, introducing several key advancements over its predecessors. It is available in multiple sizes (1B, 4B, 12B, and 27B), allowing for a flexible trade-off between performance and resource requirements. For this research, the 4B or 12B models are particularly relevant, offering powerful capabilities that can be reasonably deployed on institutional-grade hardware.

The architecture of Gemma 3 is based on the decoder-only Transformer. The foundational mechanism of the Transformer is scaled dot-product attention, calculated as:
$$ \text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V $$
where $Q$ (Queries), $K$ (Keys), and $V$ (Values) are matrices representing the input sequence, and $d_k$ is the dimension of the keys. To capture different relational aspects of the context, this is extended to \textbf{Multi-Head Attention (MHA)}, where multiple attention "heads" operate in parallel. For each head $i$ out of $h$ total heads, separate linear projections are learned: $W_i^Q, W_i^K, W_i^V$. The output of each head is:
$$ \text{head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V) $$
The final output is the concatenation of all head outputs, passed through a final linear projection $W^O$:
$$ \text{MHA}(Q, K, V) = \text{Concat}(\text{head}_1, ..., \text{head}_h)W^O $$
While powerful, MHA is memory-intensive during inference because it requires caching the Key and Value matrices for each of the $h$ heads.

Gemma 3's architecture incorporates several major innovations to enhance performance and efficiency:
\begin{itemize}
    \item \textbf{Efficient Attention Mechanisms:} Gemma 3 utilizes \textbf{Grouped-Query Attention (GQA)}, a more efficient variant of MHA \cite{FIND_CITATION_PLEASE}. In GQA, instead of having $h$ independent key and value heads, the query heads are divided into $g$ groups, where all heads within a group share the same key and value projection. This significantly reduces the size of the KV cache from being proportional to $h$ to being proportional to $g$ (where $g < h$), lowering memory requirements and enabling faster inference.
    \item \textbf{Extended Context Window:} Gemma 3 supports a significantly larger context window of up to 128,000 tokens. This is made computationally feasible by architectural efficiencies like GQA and the use of local, sliding-window attention layers, which restrict the attention calculation to a smaller, fixed-size window of tokens for most layers \cite{FIND_CITATION_PLEASE}.
    \item \textbf{Multimodal Input (Image and Text):} Unlike previous text-only versions, Gemma 3 models (with the exception of the 1B variant) are inherently multimodal. They integrate a 400M parameter variant of the SigLIP vision encoder, which allows the model to process and understand images as part of its input context \cite{FIND_CITATION_PLEASE}.
    \item \textbf{Advanced Agentic Capabilities:} Gemma 3 has built-in function calling capabilities, allowing it to interact with external tools and APIs in a structured manner. This is essential for the Intervention and Triage agents to execute tasks beyond simple text generation \cite{FIND_CITATION_PLEASE}.
\end{itemize}
This combination of multimodal understanding, long-context efficiency, and agentic capabilities makes Gemma 3 a powerful and highly suitable choice for the locally-hosted component of this thesis's hybrid AI strategy.

% --- DESCRIPTION FOR A DIAGRAM ---
% You could add a diagram here with the following description:
% \begin{figure}[htbp]
%   \centering
%   % \includegraphics[width=\textwidth]{path/to/your/diagram.png}
%   \caption{Comparison of Attention Mechanisms. The diagram visually contrasts two architectures. Part (a) titled "Multi-Head Attention (MHA)" shows an input sequence leading to multiple, independent sets of Query, Key, and Value projection layers (e.g., 8 sets). Part (b) titled "Grouped-Query Attention (GQA) in Gemma 3" shows the same input leading to the same number of Query projection layers, but these are visually grouped (e.g., in sets of 4) and point to a smaller number of shared Key and Value projection layers (e.g., 2 sets). This illustrates the reduction in KV heads, which is the source of GQA's efficiency.}
%   \label{fig:gemma3_attention_arch}
% \end{figure}

\subsubsection{Cloud-Based API Models: The Gemini 2.5 Family}

To complement the locally-hosted model, the framework integrates a state-of-the-art, proprietary model accessed via a cloud API. The Gemini family, specifically the flagship \textbf{Gemini 2.5 Pro} model, serves this role, providing a level of reasoning and multimodal understanding that is critical for handling the most complex tasks and ensuring system robustness. While a detailed architectural schematic is not public, in line with the proprietary nature of frontier AI models, its capabilities have been extensively documented by Google through official developer guides and announcements \cite{FIND_CITATION_PLEASE}.

Gemini 2.5 Pro builds upon the efficient \textbf{Mixture-of-Experts (MoE) Transformer} architecture of its predecessors. In an MoE architecture, the model is composed of numerous smaller "expert" neural networks. For any given input, a routing mechanism activates only a sparse subset of these experts. This allows the model to have a very large total parameter count—enabling vast knowledge and capability—while keeping the computational cost for any single inference relatively low.

The strategic role of Gemini 2.5 Pro in this framework is defined by its next-generation capabilities:
\begin{itemize}
    \item \textbf{Native Multimodality with Expressive Audio:} A significant architectural leap in Gemini 2.5 is its native handling of audio. Unlike models that first transcribe audio to text, Gemini 2.5 processes audio streams directly. This allows it to understand not just the words, but also the nuances of human speech such as tone, pitch, and prosody, which is invaluable for a mental health application where user sentiment is key \cite{FIND_CITATION_PLEASE}.
    \item \textbf{Controllable Reasoning and "Thinking Time":} Gemini 2.5 introduces a "thinking budget," a mechanism that allows developers to control the trade-off between response latency and reasoning depth. For high-frequency tasks performed by the Triage Agent, a lower budget can ensure speed. For complex analytical tasks required by the Analytics Agent, a higher budget can be allocated to allow for more thorough reasoning, providing granular control over both cost and quality.
    \item \textbf{Advanced Agentic Capabilities and Tool Use:} The model is explicitly designed to power advanced agents. It features more reliable and sophisticated function calling, enabling seamless integration with external tools and APIs. This is essential for the Intervention Agent to execute multi-step plans, such as triggering an email campaign based on analytical insights.
    \item \textbf{High-Fidelity Reasoning and Fallback:} As a frontier model, Gemini 2.5 Pro serves as the high-capability engine for the most demanding requests and as a crucial fallback mechanism. If the local Gemma 3 model fails or returns a low-confidence result, the system can route the query to the Gemini API, ensuring service continuity and the highest quality output.
\end{itemize}
By integrating Gemini 2.5 Pro via its API, the agentic framework gains access to state-of-the-art reasoning power on demand, ensuring that it can handle a wide spectrum of tasks with both efficiency and exceptional quality.


\subsubsection{Multilingual Understanding: The XLM-RoBERTa Model}
\label{subsubsec:xlm-roberta}

To address the multilingual nature of the chat logs, which are expected to contain English, Indonesian, and code-mixed language, a specialized model is required for the Safeguard LLM component. \textbf{XLM-RoBERTa (XLM-R)} is an encoder-only Transformer model specifically designed for high-performance cross-lingual understanding \cite{FIND_CITATION_PLEASE}. Its architecture is based on RoBERTa, which itself is a robustly optimized version of BERT, but its key innovation lies in its training methodology.

XLM-R is pre-trained on a massive, curated dataset of over 2.5 terabytes of text from the CommonCrawl corpus, spanning 100 different languages, including Indonesian. Unlike previous cross-lingual models that required parallel data or explicit translation objectives, XLM-R's power comes from being trained at scale using only a \textbf{Masked Language Modeling (MLM)} objective.

The mathematical intuition behind the MLM objective is to predict a randomly masked token in a sequence based on its surrounding context. Given a sequence of tokens $X = \{x_1, x_2, ..., x_n\}$, a corrupted version $\tilde{X}$ is created by replacing a subset of tokens with a special `[MASK]` token. The model is then trained to minimize the cross-entropy loss between its predictions and the original tokens. The objective function can be expressed as:

$$ \mathcal{L}_{MLM}(\theta) = - \sum_{i \in \mathcal{M}} \log p(x_i | \tilde{X}; \theta) $$

where $\mathcal{M}$ is the set of indices of the masked tokens and $\theta$ represents the model's parameters.

By applying this objective to a vast corpus containing 100 languages, the model is forced to develop a shared, high-dimensional embedding space where similar concepts from different languages are mapped to nearby vectors. For example, the model learns that the English word "student" and the Indonesian word "mahasiswa" often appear in similar contexts (e.g., with words like "university," "learn," "exam") and thus assigns them similar vector representations.

% --- DESCRIPTION FOR A DIAGRAM ---
% You could add a diagram here with the following description:
% \begin{figure}[htbp]
%   \centering
%   % \includegraphics[width=0.8\textwidth]{path/to/your/diagram.png}
%   \caption{Conceptual Depiction of XLM-RoBERTa's Shared Embedding Space. The diagram shows a 3D vector space. In one region, the English word "student", the Indonesian word "mahasiswa", and the Spanish word "estudiante" are clustered closely together. In another distinct region, the words "university", "universitas", and "universidad" are clustered. This illustrates how the model learns cross-lingual semantic similarities through its training objective.}
%   \label{fig:xlm_embedding_space}
% \end{figure}

This learned shared representation enables a powerful capability known as \textbf{zero-shot cross-lingual transfer}. It means that a model fine-tuned for a specific task (like Named Entity Recognition for PII) on a single language (e.g., English) can then perform that same task on other languages it was pre-trained on (e.g., Indonesian) with a high degree of accuracy, often without seeing any task-specific examples in that second language. This makes XLM-RoBERTa an ideal candidate for the generalist component of the Safeguard LLM pipeline, capable of handling mixed-language text where specialized monolingual models might fail.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SubSection: LLM Orchestration Frameworks (LangChain)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{LLM Orchestration Frameworks (LangChain)}
\label{subsec:langchain}

While LLMs provide powerful reasoning capabilities, they are inherently stateless and lack direct access to external data or tools. An LLM, in isolation, cannot query a database, call an API, or access a private document. To build sophisticated, stateful applications that overcome these limitations, an orchestration framework is required. \textbf{LangChain} is an open-source framework designed specifically for this purpose, providing the essential "glue" to connect LLMs with external resources and compose them into complex applications \cite{FIND_CITATION_PLEASE}.

The core philosophy of LangChain is to provide modular components that can be "chained" together to create complex workflows. The most recent and fundamental abstraction in LangChain is the \textbf{LangChain Expression Language (LCEL)}. LCEL provides a declarative, composable syntax for building chains, where the pipe (`|`) operator streams the output of one component into the input of the next. Every component in an LCEL chain is a "Runnable," a standardized interface that supports synchronous, asynchronous, batch, and streaming invocations, making it highly versatile for production environments \cite{FIND_CITATION_PLEASE}.

A simple LCEL chain can be represented as:
$$ \text{Chain} = \text{PromptTemplate} \ | \ \text{LLM} \ | \ \text{OutputParser} $$
In this sequence, user input is first formatted by a `PromptTemplate`, the result is passed to the `LLM` for processing, and the LLM's raw output is then transformed into a structured format (e.g., JSON) by an `OutputParser`.

For this thesis, the most critical application of LangChain is its ability to create \textbf{agents}. A LangChain agent uses an LLM not just for text processing, but as a reasoning engine to make decisions. This is often based on a framework known as \textbf{ReAct (Reasoning and Acting)}, which enables the LLM to synergize reasoning and action \cite{FIND_CITATION_PLEASE}. The agent is given access to a set of \textbf{Tools}—which are simply functions that can interact with the outside world (e.g., a database query function, a file reader, a web search API). The agent's operational loop, managed by an \textbf{Agent Executor}, can be formalized as an iterative process.

Let $G$ be the initial goal and $H_t$ be the history of actions and observations up to step $t$. The process at each step $t$ is:
\begin{enumerate}
    \item \textbf{Reasoning (Thought Generation):} The agent generates a thought $th_t$ and a subsequent action $a_t$ by sampling from the LLM's conditional probability distribution, given the goal and the history so far.
    $$ (th_t, a_t) \sim p(th, a | G, H_{t-1}; \theta_{LLM}) $$
    The prompt to the LLM contains the goal and the trajectory of previous thoughts, actions, and observations, guiding its next decision.

    \item \textbf{Action Execution:} The Agent Executor parses $a_t$ to identify the chosen tool and its input, then executes it to produce an observation, $o_t$.
    $$ o_t = \text{ExecuteTool}(a_t) $$

    \item \textbf{History Augmentation:} The new observation is appended to the history, forming the context for the next iteration.
    $$ H_t = H_{t-1} \oplus (a_t, o_t) $$
    This loop continues until the LLM determines the goal $G$ is met and generates a final answer.
\end{enumerate}
This iterative loop is what transforms a passive LLM into a proactive, problem-solving agent. For example, the \textbf{Analytics Agent} in this framework, when tasked with "summarizing student stress trends," would use this loop to formulate a SQL query (Thought and Action), execute it (Observation), and then use the results to generate a final summary. This orchestration is fundamental to enabling the autonomous capabilities central to this thesis.

% --- DESCRIPTION FOR A DIAGRAM ---
% You could add a diagram here with the following description:
% \begin{figure}[htbp]
%   \centering
%   % \includegraphics[width=\textwidth]{path/to/your/diagram.png}
%   \caption{Conceptual Diagram of a LangChain Agent based on the ReAct Framework. The diagram shows a central box labeled "Agent (LLM Reasoning Core)". An arrow labeled "Goal/Input" points to this box. From the agent box, several arrows point outwards to a set of boxes labeled "Tools", such as "Database Query", "Web Search", and "Calculator". The agent box has a looping arrow on it labeled "Thought -> Action -> Observation". An arrow labeled "Final Answer" points away from the agent box, showing the result after the loop is complete. This visualizes how the LLM core decides which tool to use to accomplish a goal.}
%   \label{fig:langchain_agent}
% \end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SubSection: Workflow Automation Platforms (n8n)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Workflow Automation Platforms (n8n)}
\label{subsec:n8n}

If an LLM orchestration framework like LangChain provides the "brain" for an individual agent, a workflow automation platform provides the "nervous system" for the entire multi-agent framework. While LangChain excels at creating complex, stateful logic within a single application, workflow automation platforms are designed to connect disparate systems and orchestrate processes across them. This research utilizes \textbf{n8n}, an open-source, node-based workflow automation tool, to manage the high-level scheduling and system-to-system communication required by the agentic framework \cite{FIND_CITATION_PLEASE}.

The theoretical foundation for such platforms can be understood through the concept of a \textbf{Directed Acyclic Graph (DAG)}. A workflow in n8n is a DAG where each node represents a specific task or operation, and the directed edges represent the flow of data and execution from one node to the next. A workflow, $W$, can be formally defined as a graph $W = (N, E)$, where:
\begin{itemize}
    \item $N$ is a set of nodes, where each node $n \in N$ represents a discrete unit of work (e.g., an API call, a database query, an email function).
    \item $E$ is a set of directed edges $(n_i, n_j)$, where an edge represents that the output of node $n_i$ becomes the input for node $n_j$.
\end{itemize}
The acyclic nature of the graph ensures that workflows have a clear start and end and do not enter into infinite loops.

The key components of n8n that are leveraged in this thesis are:
\begin{enumerate}
    \item \textbf{Trigger Nodes:} These are the starting points of a workflow and are activated by specific events. For this research, the most critical trigger is the \textbf{Cron node}, which allows for time-based scheduling. This is used to activate the \textbf{Analytics Agent} at regular intervals (e.g., every Sunday at midnight) to ensure consistent, automated trend analysis without manual intervention.
    \item \textbf{Regular Nodes:} These nodes perform the actual work. Each node is an abstraction for a specific service or function. For instance, an \textbf{HTTP Request node} is used to call the API endpoints exposed by the FastAPI backend, thereby invoking the LangChain agents. Other nodes, like the \textbf{Gmail node}, can be used to send notifications or reports generated by the agents.
    \item \textbf{Visual Workflow Management:} Unlike writing complex scripts, n8n provides a visual interface for building, debugging, and modifying these workflows. This visual representation of the DAG makes the high-level logic of the system transparent and easy to manage, which is crucial for maintaining a complex multi-agent system.
\end{enumerate}
In this architecture, n8n does not concern itself with the internal reasoning of the agents (which is handled by LangChain), but rather with the high-level orchestration: when to wake an agent up, how to pass data between agent calls, and how to connect the agentic framework to external services like email. This separation of concerns creates a robust and modular system.

% --- DESCRIPTION FOR A DIAGRAM ---
% You could add a diagram here with the following description:
% \begin{figure}[htbp]
%   \centering
%   % \includegraphics[width=\textwidth]{path/to/your/diagram.png}
%   \caption{Example n8n Workflow for the Analytics Agent. The diagram shows a sequence of connected nodes. The first node is a "Cron" trigger labeled "Every Sunday at 00:00". An arrow connects it to an "HTTP Request" node labeled "POST /api/agents/generate-report". An arrow from this node connects to an "IF" node that checks if the request was successful. The "True" branch leads to a "Gmail" node labeled "Send Report to Admin", while the "False" branch leads to another "Gmail" node labeled "Send Error Alert". This visualizes the automated, scheduled execution of an agent.}
%   \label{fig:n8n_workflow}
% \end{figure}
% PLACEHOLDER UNTUK GAMBAR/DIAGRAM
% \begin{figure}[htbp]
%   \centering
%   % \includegraphics[width=0.8\textwidth]{placeholder_diagram_ai_support_models.png} % Ganti dengan file gambar Anda
%   \fbox{\parbox[c][10cm][c]{0.8\textwidth}{\centering Gambar Placeholder: Diagram Taksonomi atau Perbandingan Model AI Konversasional untuk Dukungan Mahasiswa (misal: Rule-based vs. Retrieval vs. Generative vs. Hybrid)}}
%   \caption{Perbandingan Pendekatan dalam Pengembangan AI Konversasional untuk Dukungan Mahasiswa.}
%   \label{fig:ai_support_models}
% \end{figure}

% PLACEHOLDER UNTUK TABEL
% \begin{table}[htbp]
%   \centering
%   \caption{Ringkasan Studi Kunci Terkait Gamifikasi dalam Pendidikan Tinggi (Versi Diperbarui).}
%   \label{tab:gamifikasi_studi_kunci_revised}
%   \begin{tabular}{|p{0.2\textwidth}|p{0.3\textwidth}|p{0.25\textwidth}|p{0.2\textwidth}|}
%     \hline
%     \textbf{Referensi} & \textbf{Fokus/Masalah} & \textbf{Kontribusi Utama} & \textbf{Keterbatasan Utama} \\
%     \hline
%     \cite{gamification_higher_ed_review_2023} & Tinjauan sistematis gamifikasi di PT & Pemetaan lanskap riset, identifikasi potensi & Variabilitas implementasi, kurangnya analisis empiris seragam \\
%     \hline
%     \cite{hanus_longitudinal_gamification_2015} & Dampak longitudinal gamifikasi di kelas & Wawasan efek jangka panjang pada motivasi, performa & Konteks kelas spesifik, mungkin perlu replikasi \\
%     \hline
%     \cite{challenges_gamification_higher_ed_2022} & Tantangan dan risiko gamifikasi & Identifikasi potensi superfisialitas, penekanan berlebih pada kompetisi & Bersifat tinjauan naratif, perlu studi empiris lebih lanjut \\
%     \hline
%     \cite{taskin_player_types_gamification_2022} & Tipe pemain dan personalisasi gamifikasi & Menyoroti pentingnya desain adaptif & Lebih fokus pada kerangka tipe pemain, kurang evaluasi implementasi personalisasi \\
%     \hline
%   \end{tabular}
% \end{table}

% ==================================================================================
% Bagian selanjutnya dari Bab 2 (Dasar Teori, Analisis Perbandingan Metode, dll.)
% akan mengikuti struktur templat yang Anda berikan. 
% Anda perlu mengembangkannya dengan detail yang sesuai.
% ==================================================================================

\section{Literature Review}
\label{sec:literature_review}

% (Konten Dasar Teori seperti draf sebelumnya, namun pastikan untuk mengembangkannya secara detail)
Bagian ini memaparkan landasan konseptual dan teoritis yang relevan dengan komponen-komponen utama platform yang diusulkan. Pemahaman mendalam terhadap teori ini esensial untuk perancangan sistem yang efektif dan evaluasi yang valid. Sumber utama bagian ini adalah buku referensi, artikel tinjauan (\textit{review articles}), dan publikasi ilmiah fundamental di bidang terkait.


\section{Analisis Perbandingan Metode}
\label{sec:analisis_metode_revised}

Di dalam tinjauan pustaka hasil akhirnya adalah analisis secara kualitatif atau pun secara kuantitatif kelebihan dan kekurangan metode jika dikaitkan dengan masalah, batasan-batasan masalah dan solusi yang dinginkan. Analisis kuantitatif tidak wajib teapi mempunyai nilai tambah di dalam tugas akhir saudara. Bagian ini menjelaskan kenapa metode tersebut dipilih dan uraikan dengan lebih jelas metode pelaksanaan tugas akhir yang ingin Anda lakukan. 
% (Kembangkan dengan analisis pendekatan metodologis alternatif dan justifikasi DSR)

\section{Pertanyaan Tugas Akhir (Jika Perlu)}
\label{sec:pertanyaan_ta_revised}

Pertanyaan tugas akhir bersifat opsional dan dapat ditambahkan untuk menekankan hal-hal yang hendak diketahui dari tugas akhir berdasar pada tujuan tugas akhir. Pertanyaan tugas akhir dikenal dengan RQ (\textit{Research Question}) dan harus memiliki keterkaitan dengan RO (\textit{Research Objective}). Satu RO dapat memiliki satu atau lebih dari satu RQ.
