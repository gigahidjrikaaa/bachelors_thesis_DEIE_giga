\chapter{Literature Review and Theoretical Background}

% Bab ini mengulas fondasi konseptual dan empiris yang melandasi penelitian mengenai platform terintegrasi berbasis AI, gamifikasi, dan blockchain untuk keterlibatan dan kesejahteraan mahasiswa. Bagian pertama menyajikan tinjauan pustaka terhadap karya-karya terdahulu yang relevan, mengidentifikasi kontribusi serta keterbatasan mereka, dan memposisikan penelitian ini dalam lanskap keilmuan saat ini. Bagian kedua memaparkan dasar-dasar teori mengenai teknologi inti yang digunakan (AI Konversasional Hibrida, Gamifikasi, Blockchain) serta konsep keterlibatan pengguna dan kesejahteraan mahasiswa dalam konteks digital. Terakhir, bab ini menganalisis secara komparatif pendekatan-pendekatan yang ada dan justifikasi pemilihan metode untuk penelitian ini.

This chapter provides the theoretical foundations and academic context for the research. The first section, Theoretical Background, explains the core concepts and technologies that constitute the proposed framework. The second section, Literature Review, surveys existing work in related fields to identify the research gap that this thesis aims to address.

\section{Theoretical Background}
\label{sec:theoretical_background}

This section describes the foundational principles and technologies upon which the agentic AI framework is built, including Agentic AI, Large Language Models (LLMs), LLM orchestration, and workflow automation platforms.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SubSection: Agentic AI, Multi-Agent Systems, and LLMs
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Agentic AI and Multi-Agent Systems (MAS)}
\label{subsec:agentic_ai}

The paradigm of Artificial Intelligence (AI) has evolved significantly from systems that perform singular, reactive tasks to those that exhibit autonomous, proactive, and social behaviors. A cornerstone of this evolution is the concept of an \textbf{intelligent agent}. An agent is not merely a program; it is a persistent computational entity with a degree of autonomy, situated within an environment, which it can both perceive and upon which it can act to achieve a set of goals or design objectives \cite{FIND_CITATION_PLEASE}. The defining characteristic of an agent is its \textbf{autonomy}—its capacity to operate independently, making decisions and initiating actions without direct, constant human intervention. This is distinct from traditional objects, which are defined by their methods and attributes but do not exhibit control over their own behavior \cite{FIND_CITATION_PLEASE}.

To operationalize this concept, this thesis formally introduces a framework built upon three distinct, specialized intelligent agents. Each agent is designed to address a specific challenge outlined in Chapter 1, and together they form the core of the proposed proactive support system. These agents are:
\begin{itemize}
    \item The \textbf{Analytics Agent}, responsible for data-driven trend identification.
    \item The \textbf{Intervention Agent}, responsible for automating proactive outreach.
    \item The \textbf{Triage Agent}, responsible for real-time user support and resource routing.
\end{itemize}
The theoretical underpinnings of these agents' architecture and behavior are drawn from established models of rational agency and multi-agent systems, as detailed below.

Fundamentally, an agent's operation is defined by a continuous cycle of perception, reasoning (or deliberation), and action. It perceives its environment through virtual \textbf{sensors} (e.g., data feeds, API calls, database queries) and influences that environment through its \textbf{actuators} (e.g., sending emails, generating reports, invoking other services) \cite{FIND_CITATION_PLEASE}. A prominent and highly relevant architecture for designing such goal-oriented agents is the \textbf{Belief-Desire-Intention (BDI)} model \cite{FIND_CITATION_PLEASE}. This model provides a framework for rational agency that mirrors human practical reasoning:
\begin{itemize}
    \item \textbf{Beliefs:} This represents the informational state of the agent—its knowledge about the environment, which may be incomplete or incorrect. For the \textbf{Analytics Agent}, beliefs correspond to the current understanding of student well-being trends derived from anonymized data.
    \item \textbf{Desires:} These are the motivational states of the agent, representing the objectives or goals it is designed to achieve. Desires can be seen as the potential tasks the agent could undertake, such as the \textbf{Intervention Agent's} overarching goal to "automate proactive outreach."
    \item \textbf{Intentions:} This represents the agent's commitment to a specific plan or course of action. An intention is a desire that the agent has chosen to actively pursue. For instance, the \textbf{Triage Agent}, upon identifying a high-severity conversation, forms an intention to immediately route the user to emergency resources.
\end{itemize}
The BDI framework allows for the design of agents that are not merely reactive but are proactive and deliberative, capable of reasoning about how to best achieve their goals given their current beliefs about the world \cite{FIND_CITATION_PLEASE}.

When multiple agents, each with its own goals and capabilities, co-exist and interact within a shared environment, they form a \textbf{Multi-Agent System (MAS)}. An MAS is a system in which the overall intelligent behavior and functionality are a product of the collective, emergent dynamics of its constituent agents \cite{FIND_CITATION_PLEASE}. The power of an MAS lies in its ability to solve problems that would be difficult or impossible for a monolithic system or a single agent to handle. This is achieved through social interaction, primarily:
\begin{itemize}
    \item \textbf{Coordination and Cooperation:} Agents must coordinate their actions to avoid interference and cooperate to achieve common goals. In this thesis, the \textbf{Analytics}, \textbf{Intervention}, and \textbf{Triage} agents must cooperate: the Analytics Agent provides the data-driven insights (beliefs) that the Intervention Agent uses to form its outreach plans (intentions), while the Triage Agent handles immediate, real-time needs that may fall outside the other agents' scopes.
    \item \textbf{Negotiation:} When agents have conflicting goals or must compete for limited resources, they must be able to negotiate to find a mutually acceptable compromise \cite{FIND_CITATION_PLEASE}.
    \item \textbf{Communication:} Effective interaction requires a shared Agent Communication Language (ACL), such as FIPA-ACL or KQML, which defines the syntax and semantics for messages, allowing agents to perform actions like requesting information, making proposals, and accepting or rejecting tasks \cite{FIND_CITATION_PLEASE}.
\end{itemize}
Therefore, this thesis leverages the MAS paradigm by designing a framework composed of three specialized, collaborative agents. Their individual, goal-directed behaviors, orchestrated within a hybrid architecture, work in concert to achieve the overarching systemic objective: transforming institutional mental health support from a reactive model to a proactive, data-driven ecosystem.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SubSection: Large Language Models (LLMs)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Large Language Models (LLMs)}
\label{subsec:llms}

Large Language Models (LLMs) are a class of deep learning models that have demonstrated remarkable capabilities in understanding and generating human-like text. The architectural foundation for virtually all modern LLMs, including the Gemma and Gemini models used in this research, is the \textbf{Transformer architecture}, first introduced by Vaswani et al. \cite{FIND_CITATION_PLEASE}. The Transformer's key innovation is the \textbf{self-attention mechanism}, which allows the model to dynamically weigh the importance of different words in an input sequence when processing and generating language. This enables the model to capture complex, long-range dependencies and contextual relationships far more effectively than its predecessors, such as Recurrent Neural Networks (RNNs) \cite{FIND_CITATION_PLEASE}.

The core operation of a Transformer-based model involves processing input text through a series of encoding and/or decoding layers. In a generative, decoder-only model like Gemma, the process can be conceptualized as follows:
\begin{enumerate}
    \item \textbf{Tokenization and Embedding:} Input text is first broken down into smaller units called tokens. Each token is then mapped to a high-dimensional vector, or an "embedding," that represents its semantic meaning.
    \item \textbf{Positional Encoding:} Since the self-attention mechanism does not inherently process sequential order, a positional encoding vector is added to each token embedding to provide the model with information about the word's position in the sequence.
    \item \textbf{Self-Attention Layers:} The sequence of embeddings passes through multiple self-attention layers. In each layer, the model calculates attention scores for every token relative to all other tokens in the sequence, effectively learning which parts of the input are most relevant for understanding the context of each specific token.
    \item \textbf{Feed-Forward Networks:} Each attention layer is followed by a feed-forward neural network that applies further transformations to each token's representation.
    \item \textbf{Output Generation:} The model's final output is a probability distribution over its entire vocabulary for the next token in the sequence. The model then typically selects the most likely token (or samples from the distribution) and appends it to the input, repeating the process autoregressively to generate coherent text \cite{FIND_CITATION_PLEASE}.
\end{enumerate}

\begin{figure}[htbp]
  \centering
  % \includegraphics[width=\textwidth]{placeholder_diagram_transformer.png} % Ganti dengan file gambar Anda
  \fbox{\parbox[c][8cm][c]{0.9\textwidth}{\centering \textbf{Placeholder for Diagram: Simplified Transformer Architecture for Generative LLMs} \\ \vspace{1cm} This diagram should illustrate the flow of information: \\ 1. Input Text -> Tokenizer \\ 2. Tokens -> Embedding Layer + Positional Encoding \\ 3. Embedded Tokens -> A stack of 'N' Decoder Blocks \\ 4. Inside a Decoder Block: Multi-Head Self-Attention -> Feed-Forward Network \\ 5. Final Output -> Linear Layer -> Softmax -> Probability of Next Token}}
  \caption{A simplified view of the decoder-only Transformer architecture used in generative LLMs like Gemma. The model processes input embeddings through multiple layers of self-attention and feed-forward networks to predict the next token in a sequence.}
  \label{fig:transformer_architecture}
\end{figure}

This research utilizes a \textbf{hybrid LLM strategy} that leverages two distinct families of models based on this architecture to balance performance, privacy, and capability:
\begin{itemize}
    \item \textbf{Locally-Hosted Open Models (Gemma):} The Gemma models are a family of lightweight, open-weight models developed by Google, built from the same research and technology used to create the Gemini models \cite{FIND_CITATION_PLEASE}. As decoder-only Transformers, they are optimized for generative text tasks. Being "open-weight" means their parameters are publicly available, allowing them to be deployed on institutional hardware. This approach is critical for this project as it guarantees data privacy and security—sensitive student conversations processed by the Triage Agent never leave the university's secure servers. Furthermore, local hosting provides low latency and eliminates per-token API costs, making it a sustainable choice for real-time, high-volume interactions.
    \item \textbf{Cloud-Based API Models (Gemini):} The Gemini models represent Google's state-of-the-art, natively multimodal foundation models, available in various sizes (e.g., Gemini Pro). Unlike models trained solely on text, Gemini was pre-trained from the ground up on multiple data modalities, giving it more sophisticated reasoning capabilities \cite{FIND_CITATION_PLEASE}. In this framework, a powerful model like Gemini Pro is accessed via a secure API for complex, non-sensitive tasks, such as the weekly trend analysis performed by the Analytics Agent. It also serves as a robust fallback mechanism, ensuring service continuity and reliability should the local model encounter issues.
\end{itemize}

\subsection{LLM Orchestration Frameworks (LangChain)}
\label{subsec:langchain}

An LLM, in isolation, is a powerful text processor but lacks the ability to perform complex, multi-step tasks or interact with external systems. This limitation is addressed by LLM orchestration frameworks like \textbf{LangChain} \cite{FIND_CITATION_PLEASE}. LangChain is a software development framework that provides modular components for building applications powered by LLMs.

Key components of LangChain utilized in this research include:
\begin{itemize}
    \item \textbf{Chains:} Sequences of calls, either to an LLM or another utility, that allow for complex, multi-step logic.
    \item \textbf{Agents and Tools:} LangChain allows the creation of agents that use an LLM as a reasoning engine to decide which "tools" to use. A tool can be any function, such as a database query, a calculation, or an API call.
    \item \textbf{Retrieval-Augmented Generation (RAG):} This technique allows an LLM to access and incorporate information from external knowledge bases before generating a response, which is crucial for providing context-aware answers.
\end{itemize}
In this thesis, LangChain serves as the core of the "Brain" within the FastAPI backend, enabling the development of the sophisticated logic required by the three agents.

\subsection{Workflow Automation Platforms (n8n)}
\label{subsec:n8n}

Modern software systems rarely exist in isolation. The ability to integrate disparate systems and automate data flows is critical for operational efficiency. \textbf{Workflow Automation Platforms} are designed for this purpose \cite{FIND_CITATION_PLEASE}. These platforms provide a visual interface to connect various applications, databases, and APIs into automated sequences, or "workflows."

This project utilizes \textbf{n8n}, an open-source workflow automation tool. Unlike a general-purpose programming language, n8n excels at tasks involving scheduling, event triggers, and system-to-system communication. In our architecture, n8n functions as the "Nervous System," responsible for:
\begin{itemize}
    \item **Scheduled Triggers:** Running tasks at specific times (e.g., triggering the Analytics Agent every Sunday via a Cron job).
    \item **API Integration:** Calling the API endpoints exposed by our FastAPI backend and communicating with external services (e.g., an email server).
    \item **Visual Workflow Management:** Providing a clear, visual representation of the automated processes, which simplifies debugging and modification.
\end{itemize}

% PLACEHOLDER UNTUK GAMBAR/DIAGRAM
% \begin{figure}[htbp]
%   \centering
%   % \includegraphics[width=0.8\textwidth]{placeholder_diagram_ai_support_models.png} % Ganti dengan file gambar Anda
%   \fbox{\parbox[c][10cm][c]{0.8\textwidth}{\centering Gambar Placeholder: Diagram Taksonomi atau Perbandingan Model AI Konversasional untuk Dukungan Mahasiswa (misal: Rule-based vs. Retrieval vs. Generative vs. Hybrid)}}
%   \caption{Perbandingan Pendekatan dalam Pengembangan AI Konversasional untuk Dukungan Mahasiswa.}
%   \label{fig:ai_support_models}
% \end{figure}

% PLACEHOLDER UNTUK TABEL
% \begin{table}[htbp]
%   \centering
%   \caption{Ringkasan Studi Kunci Terkait Gamifikasi dalam Pendidikan Tinggi (Versi Diperbarui).}
%   \label{tab:gamifikasi_studi_kunci_revised}
%   \begin{tabular}{|p{0.2\textwidth}|p{0.3\textwidth}|p{0.25\textwidth}|p{0.2\textwidth}|}
%     \hline
%     \textbf{Referensi} & \textbf{Fokus/Masalah} & \textbf{Kontribusi Utama} & \textbf{Keterbatasan Utama} \\
%     \hline
%     \cite{gamification_higher_ed_review_2023} & Tinjauan sistematis gamifikasi di PT & Pemetaan lanskap riset, identifikasi potensi & Variabilitas implementasi, kurangnya analisis empiris seragam \\
%     \hline
%     \cite{hanus_longitudinal_gamification_2015} & Dampak longitudinal gamifikasi di kelas & Wawasan efek jangka panjang pada motivasi, performa & Konteks kelas spesifik, mungkin perlu replikasi \\
%     \hline
%     \cite{challenges_gamification_higher_ed_2022} & Tantangan dan risiko gamifikasi & Identifikasi potensi superfisialitas, penekanan berlebih pada kompetisi & Bersifat tinjauan naratif, perlu studi empiris lebih lanjut \\
%     \hline
%     \cite{taskin_player_types_gamification_2022} & Tipe pemain dan personalisasi gamifikasi & Menyoroti pentingnya desain adaptif & Lebih fokus pada kerangka tipe pemain, kurang evaluasi implementasi personalisasi \\
%     \hline
%   \end{tabular}
% \end{table}

% ==================================================================================
% Bagian selanjutnya dari Bab 2 (Dasar Teori, Analisis Perbandingan Metode, dll.)
% akan mengikuti struktur templat yang Anda berikan. 
% Anda perlu mengembangkannya dengan detail yang sesuai.
% ==================================================================================

\section{Literature Review}
\label{sec:literature_review}

% (Konten Dasar Teori seperti draf sebelumnya, namun pastikan untuk mengembangkannya secara detail)
Bagian ini memaparkan landasan konseptual dan teoritis yang relevan dengan komponen-komponen utama platform yang diusulkan. Pemahaman mendalam terhadap teori ini esensial untuk perancangan sistem yang efektif dan evaluasi yang valid. Sumber utama bagian ini adalah buku referensi, artikel tinjauan (\textit{review articles}), dan publikasi ilmiah fundamental di bidang terkait.


\section{Analisis Perbandingan Metode}
\label{sec:analisis_metode_revised}

Di dalam tinjauan pustaka hasil akhirnya adalah analisis secara kualitatif atau pun secara kuantitatif kelebihan dan kekurangan metode jika dikaitkan dengan masalah, batasan-batasan masalah dan solusi yang dinginkan. Analisis kuantitatif tidak wajib teapi mempunyai nilai tambah di dalam tugas akhir saudara. Bagian ini menjelaskan kenapa metode tersebut dipilih dan uraikan dengan lebih jelas metode pelaksanaan tugas akhir yang ingin Anda lakukan. 
% (Kembangkan dengan analisis pendekatan metodologis alternatif dan justifikasi DSR)

\section{Pertanyaan Tugas Akhir (Jika Perlu)}
\label{sec:pertanyaan_ta_revised}

Pertanyaan tugas akhir bersifat opsional dan dapat ditambahkan untuk menekankan hal-hal yang hendak diketahui dari tugas akhir berdasar pada tujuan tugas akhir. Pertanyaan tugas akhir dikenal dengan RQ (\textit{Research Question}) dan harus memiliki keterkaitan dengan RO (\textit{Research Objective}). Satu RO dapat memiliki satu atau lebih dari satu RQ.
