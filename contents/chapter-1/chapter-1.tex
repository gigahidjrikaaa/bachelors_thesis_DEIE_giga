\chapter{Introduction}
\label{chap:introduction}

\section{Background}
\label{sec:background}

\textbf{Evolution of Conversational AI: From Chatbots to Agentic Systems.}
The landscape of conversational AI has undergone a fundamental transformation over the past decade. Early rule-based chatbots operated through predefined decision trees and pattern matching, limiting their utility to narrow, predictable interaction domains \cite{weizenbaum1966eliza}. The advent of Large Language Models (LLMs) marked a paradigm shift: these transformer-based architectures, trained on vast corpora, demonstrated emergent capabilities in natural language understanding, generation, and in-context learning \cite{brown2020gpt3, openai2024gpt4}. Modern LLMs can engage in nuanced, multi-turn dialogue, reason about complex problems, and adapt their responses based on conversational context.

However, a critical limitation persists. Standard LLM-based chatbots remain fundamentally \textbf{reactive}: they respond to user queries but cannot autonomously perceive environmental states, make decisions, or execute actions toward goals. This constraint creates what the literature terms an \textit{insight-to-action gap}, where systems provide information or recommendations but depend on human operators to interpret and act upon their outputs \cite{jorno2018actionableinsight, susnjak2022dashboard}. The gap is particularly problematic in domains requiring timely intervention, where delays between insight generation and action execution may have consequential outcomes.

The emergence of \textbf{Agentic AI} represents the next evolutionary stage. An intelligent agent, as formalized in the multi-agent systems literature, is an autonomous entity capable of perception, deliberation, and proactive action to achieve specified goals \cite{wooldridge2009introductionmas, saleem2025multiagent}. Unlike passive chatbots, agentic systems can monitor environmental states continuously, detect conditions requiring intervention, and execute complex workflows without explicit user initiation. This capability transforms AI from an information tool into an autonomous actor within organizational processes.

\textbf{Engineering Challenges in Agentic System Development.}
Building agentic AI systems for safety-critical domains introduces substantial engineering challenges that extend beyond standard software development. These challenges motivate the architectural decisions presented in this thesis.

Agentic workflows are inherently stateful: a multi-turn interaction must maintain context across messages, track decision histories, and coordinate handoffs between specialized components. Traditional request-response architectures fail to capture this complexity. Graph-based orchestration frameworks, such as LangGraph \cite{langgraph2024}, address this by modeling workflows as state machines with explicit nodes (processing steps), edges (transitions), and typed state schemas. This formalization enables predictable behavior, facilitates debugging, and supports formal verification of workflow correctness.

Agentic systems derive their utility from tool use: the ability to invoke external services, query databases, or trigger administrative actions. However, tool invocations introduce failure modes, including network timeouts, rate limits, and schema validation errors, that must be handled gracefully. Robust agentic architectures implement idempotent tool calls, exponential backoff for retries, and transaction-like semantics to ensure workflows complete correctly despite transient failures.

When agents can take autonomous actions, the consequences of errors escalate. A misclassification in a safety-critical context may result in inappropriate interventions or, conversely, missed detections of genuine risk. Engineering for safety requires defense-in-depth: multiple overlapping safeguards including input validation, output filtering, human-in-the-loop checkpoints, and continuous monitoring. The system must be designed to fail safely, erring toward conservative actions when uncertainty is high.

Agentic systems that process sensitive data must balance analytical utility against privacy protection. Population-level insights enable data-driven decision-making, but naive aggregation may expose individual records. Privacy-preserving techniques, such as k-anonymity enforcement at the query level, enable institutions to derive actionable intelligence while mathematically guaranteeing that individuals cannot be re-identified from aggregated outputs.

\textbf{Application Domain: University Mental Health Support.}
The engineering capabilities described above find a compelling application in university mental health support, a domain characterized by scale challenges, temporal urgency, and safety-critical decision-making. Higher Education Institutions (HEIs) face a growing crisis in supporting student well-being \cite{hill2024studentwellbeing, duraku2024overcoming}. Recent global surveys indicate that nearly 42\% of university students meet the criteria for at least one mental health disorder, while the average counselor-to-student ratio remains around 1:1,500, well above recommended levels for effective service delivery \cite{lipson2022healthy, gallagher2023counselor}.

The traditional support model, centered around on-campus counseling services, is fundamentally \textbf{reactive}. It relies on students to self-identify their distress and navigate the process of seeking help. This paradigm faces significant operational challenges: insufficient staffing, long waiting lists, and inability to provide immediate 24/7 support, ultimately limiting access for a large portion of the student body \cite{baik2019universities}. Consequently, a critical gap persists between the need for mental health services and their actual provision \cite{outay2024multiagent}.

To bridge this gap, a paradigm shift from reactive to \textbf{proactive} support is imperative \cite{outay2024multiagent}. The agentic AI capabilities outlined above directly address the operational requirements for such a shift:

\begin{itemize}
    \item \textbf{Autonomous Risk Detection:} An agentic system can continuously monitor conversational patterns and detect latent crisis indicators without requiring students to explicitly request help, addressing the fundamental barrier that vulnerable students are least likely to initiate contact \cite{Duraku2025_stigma, Bahar2025_stigma}.
    \item \textbf{Automated Workflow Orchestration:} Complex administrative tasks such as appointment scheduling, case creation, and counselor notification can be executed autonomously, reducing operational burden and response latency.
    \item \textbf{Privacy-Preserving Institutional Intelligence:} Population-level trend analysis enables proactive resource allocation (e.g., identifying emerging stress patterns in specific faculties) while maintaining individual privacy.
\end{itemize}

This research proposes a \textbf{Multi-Agent System (MAS)} architecture to realize these capabilities. We posit that a framework built upon collaborative intelligent agents can create a transformative ecosystem that serves as both a support tool for students and a strategic asset for the institution, enabling data-driven decision-making, automating operational workflows, and facilitating a proactive stance on student well-being \cite{salutari2024mas}. This framework is prototyped within the \textbf{UGM-AICare Project}, a collaborative university research initiative focused on developing AI-driven mental health tools for the Universitas Gadjah Mada (UGM) community.

\textbf{Positioning the Proposed Framework.}
To clarify the paradigm shift this research proposes, Table~\ref{tab:support_paradigms} presents a systematic comparison of three mental health support models: traditional in-person counseling, reactive AI chatbots, and the proposed proactive multi-agent framework. This comparison reveals that both traditional and chatbot-based approaches share a fundamental limitation: they are \textbf{reactive systems that depend on student-initiated help-seeking behavior}. The proposed framework addresses this limitation through continuous monitoring, automated risk detection, and proactive intervention while maintaining human oversight for safety-critical decisions.

\begin{table}[htbp]
    \centering
    \caption{Comparison of mental health support paradigms: Traditional, chatbot, and proposed proactive multi-agent systems.}
    \label{tab:support_paradigms}
    \small
    \setlength{\tabcolsep}{3pt}
    \begin{tabular}{p{2.3cm}p{3.2cm}p{3.2cm}p{3.8cm}}
        \toprule
        \textbf{Characteristic} & \textbf{Traditional In-Person Counseling} & \textbf{Reactive AI Chatbots} & \textbf{Proposed Multi-Agent Framework (UGM-AICare)} \\
        \midrule
        \textbf{Initiation Model} & Student must self-refer and schedule appointment \cite{baik2019universities} & Student must open app and initiate conversation \cite{fulmer2018artificial} & Continuous monitoring with automated outreach capability; system-initiated intervention \\
        \midrule
        \textbf{Availability} & Limited office hours (typically 9am-5pm); multi-week waitlists common \cite{gallagher2023counselor} & 24/7 availability; instant response & 24/7 availability with proactive intervention triggers; automated escalation protocols \\
        \midrule
        \textbf{Scalability} & Constrained by counselor-to-student ratio (1:1500 average); unsustainable at scale \cite{lipson2022healthy} & Scales to unlimited concurrent users & Scales through automated triage and routing; human oversight reserved for critical cases \\
        \midrule
        \textbf{Data Utilization} & Manual case notes; no population-level trend analysis & Individual conversation logs; limited cross-user insights & Population-level analytics with privacy-preserving aggregation; automated intervention routing based on trends \\
        \midrule
        \textbf{Intervention Timing} & \textbf{After crisis escalates} (reactive: student seeks help post-crisis) & \textbf{After student reaches out} (reactive: depends on user initiation) & \textbf{Before crisis peaks} (proactive: automated risk detection triggers early intervention) \\
        \midrule
        \textbf{Administrative Integration} & Manual case management; human-dependent scheduling and follow-up workflows & No administrative integration; standalone conversational interface & Automated case creation, appointment scheduling, resource allocation, and counselor notification \\
        \midrule
        \textbf{Key Limitation} & \textbf{Relies entirely on student help-seeking behavior}; barriers include stigma, lack of awareness, symptom-induced apathy \cite{Jabeen2025_helpseeking, Junming2025_barriers} & \textbf{Still requires student to initiate contact}; does not reach students who avoid seeking help & Requires validation through controlled testing before clinical deployment; performance not yet validated on live student populations \\
        \midrule
        \textbf{Human Oversight} & Direct human delivery of all services & Minimal oversight; no clinical escalation path & Human-in-the-loop for all critical decisions; automated triage with mandatory counselor review \\
        \bottomrule
    \end{tabular}
\end{table}

The insight from this comparison is that technological advancement alone (moving from in-person to chatbot) does not address the fundamental barrier: \textbf{vulnerable students who need help most are precisely those least likely to initiate contact} \cite{Duraku2025_stigma, Bahar2025_stigma}. This research hypothesizes that closing this gap requires a paradigm shift from reactive to proactive support, operationalized through autonomous agent-based monitoring and intervention.


%-------------------------------------------------

\section{Problem Formulation}
\label{sec:problem_formulation}

The inefficiency and reactive nature of current university mental health support systems present a complex problem. To move towards a proactive and scalable model, this research addresses the following core challenges:

\begin{enumerate}
    \item \textbf{The Passive Nature of Current Systems:} Traditional support models and standard chatbots are fundamentally passive, waiting for students to explicitly request help. How can an agentic AI framework be designed to autonomously detect latent risk signals and initiate intervention, thereby shifting the paradigm from reactive to proactive?

    \item \textbf{Orchestrating Autonomous Intervention:} Proactive support requires the system to take independent action (e.g., scheduling appointments, escalating crises) rather than just providing information. How can a heterogeneous system of specialized agents be orchestrated to execute these complex, stateful workflows reliably and autonomously?

    \item \textbf{Validating Proactive Safety:} Validating a system that acts autonomously carries higher risk than validating a passive tool. How can the safety and efficacy of such an autonomous, proactive system be rigorously validated in a pre-clinical context to ensure it intervenes appropriately without overstepping?
\end{enumerate}

To address these challenges, this thesis proposes and details the \textbf{Safety Agent Suite}, a framework comprised of four specialized, collaborative intelligent agents: a \textbf{Safety Triage Agent (STA)}, a \textbf{Therapeutic Coach Agent (TCA)}, a \textbf{Case Management Agent (CMA)}, and an \textbf{Insights Agent (IA)}, coordinated through an \textbf{Aika Meta-Agent} (orchestrator) that provides unified, role-based orchestration and ensures coherent, safety-first interactions across all user roles.

%-------------------------------------------------	

\section{Objectives}
\label{sec:objectives}

The primary objectives of this thesis are:
\begin{enumerate}
    \item To design an agentic AI framework, grounded in the BDI model of rational agency, that enables a paradigm shift from reactive to proactive mental health support in higher education.
    \item To implement a functional proof-of-concept prototype, the 'Safety Agent Suite,' demonstrating the autonomous orchestration of specialized agents to perform system-initiated interventions (triage, coaching, service desk, insights).
    \item To evaluate the prototype's core agentic workflows through scenario-based testing, specifically validating its capacity to detect latent risks and execute automated administrative actions.
\end{enumerate}

%-------------------------------------------------

\section{Research Questions}
\label{sec:research_questions}

To keep the scope concrete and measurable, this thesis addresses the following research questions (RQs). These research questions are derived directly from the identified problems and are designed to verify whether the proposed objectives have been met or not.

\begin{enumerate}
    \item \textbf{RQ1 (Proactive Safety):} Can the agentic framework autonomously detect latent crisis indicators and initiate appropriate safety protocols without explicit user escalation?
    \item \textbf{RQ2 (Autonomous Orchestration):} Can the multi-agent architecture reliably orchestrate complex support workflows to enable system-initiated interventions (e.g., coaching, case creation) without manual user navigation?
    \item \textbf{RQ3 (Strategic Proactivity):} Can the framework generate privacy-preserving, population-level insights that enable institutional leaders to engage in proactive resource allocation?
\end{enumerate}

These questions directly inform the evaluation in Chapter IV through scenario-based tests and transparent metrics (e.g., sensitivity, state transition accuracy, rubric scores), with human oversight preserved for safety-critical cases.

%-------------------------------------------------	

\section{Scope and Limitations}
\label{sec:scope_and_limitations}

To ensure the feasibility and focus of this bachelor's thesis, the following boundaries are explicitly established:

\begin{enumerate}
    \item \textbf{Focus on Multi-Agent Architecture Only:} This research is focused exclusively on the \textbf{design, implementation, and evaluation of the multi-agent AI framework itself}, the Safety Agent Suite's BDI-based specialist agents, the Aika Meta-Agent orchestration layer, and their collective behavior in safety-critical conversational scenarios. The full UGM-AICare implementation includes database schema design, user interface components, blockchain token systems, and deployment infrastructure; however, \textbf{these system components are documented as implementation context but are not subjects of formal evaluation in this work}.

    \item \textbf{Proof-of-Concept Evaluation Scope:} The evaluation adopts a \textbf{proof-of-concept validation approach} appropriate for bachelor's-level Design Science Research. The objective is to demonstrate \textbf{technical feasibility} that the Safety Agent Suite can execute core workflows correctly under controlled conditions. Evaluation uses modest sample sizes: 50 crisis scenarios for safety triage (RQ1), 15 conversation flows for orchestration and 10 coaching scenarios for response quality (RQ2), and code review with unit tests for privacy validation (RQ3). This approach validates architectural correctness without requiring extensive data collection infrastructure, consistent with DSR artifact evaluation conventions where initial validation focuses on demonstrating capability rather than exhaustive performance characterization.

    \item \textbf{Simulated Data for Privacy and Feasibility:} All testing utilizes \textbf{synthetically generated student mental health crisis scenarios and simulated conversation patterns} created using Claude 4.5 Sonnet, not real user data. This approach is necessary to protect privacy during development and to enable controlled evaluation without requiring human subjects approval. However, it means that agent performance has not been validated on the specific linguistic diversity, cultural contexts, and edge cases of a live Indonesian student population. Ground truth labels for synthetic scenarios are provided by the primary researcher with peer validation, acknowledging that clinical expert validation remains future work.

    \item \textbf{Single-Rater Assessment with AI Validation:} Response quality evaluation (RQ2) is conducted by the primary researcher using a structured rubric, with Gemini 2.5 Pro performing independent validation on the same responses to provide a reference point for consistency. This pragmatic approach demonstrates the evaluation methodology while acknowledging that inter-rater reliability analysis with multiple clinical experts and formal therapeutic quality assessment using validated instruments (e.g., Cognitive Therapy Scale) remain future work appropriate for clinical validation studies.

    \item \textbf{Privacy-Aware Design Without Formal Proofs:} This research implements k-anonymity enforcement ($k \geq 5$) with code-level verification and unit testing to validate privacy safeguards function as designed. This demonstrates \textbf{privacy-aware agent behavior} and implementation correctness within the prototype context. However, it does not pursue full differential privacy proofs, formal threat modeling using frameworks like LINDDUN, or cryptographic verification—activities appropriate for production security audits but beyond bachelor's thesis scope.

    \item \textbf{Technical Feasibility, Not Clinical Efficacy:} This evaluation demonstrates that the proposed multi-agent architecture is \textit{technically feasible}. The agents can classify crises, orchestrate workflows, generate appropriate responses, and enforce privacy thresholds under controlled conditions. It does \textbf{not} claim to have validated clinical efficacy (long-term mental health outcome improvement), cultural appropriateness for Indonesian students, operational sustainability, or production-readiness for deployment without further testing. Such claims would require ethics approval, multi-rater expert evaluation, field pilots with real users, longitudinal outcome measurement, and cost-benefit analysis, activities beyond bachelor's thesis scope but identified as critical future work in Chapter IV, Section~\ref{sec:discussion}.
\end{enumerate}

\section{Contributions}
\label{sec:contributions}

This thesis contributes a focused blueprint and evidence base for safety‑oriented agentic support:

\begin{enumerate}
    \item \textbf{Safety pipeline specification}. A concrete guideline for triage and escalation: risk cues and scoring, guardrails and redaction steps, decision thresholds, human‑in‑the‑loop invariants, and service targets such as time‑to‑escalation.
    \item \textbf{Agent orchestration design}. A LangGraph view of the Safety Agent Suite—nodes, edges, and typed state schemas—plus the supporting tool‑use protocol (validated schemas, idempotency, retry/backoff) that keeps workflows predictable.
    \item \textbf{Evaluation assets and findings}. Scenario-based tests (synthetic crisis conversation scenarios, adversarial inputs, blinded coaching rubric) and their results, covering safety sensitivity, orchestration reliability, latency, and coaching quality under human oversight.
\end{enumerate}

\section{Thesis Outline}
\label{sec:thesis_outline}

The structure of this thesis is outlined as follows:

\textbf{Chapter I: Introduction.} This chapter elaborates on the background of the study, the justification for the research's significance, the problem formulation to be addressed, and the specific objectives to be achieved. It also defines the scope and limitations of the research, outlines the expected contributions, and presents the overall organizational structure of the thesis report.

\textbf{Chapter II: Literature Review and Theoretical Framework.} This chapter surveys prior work on agentic and conversational AI for mental health, safety-critical triage systems, human-in-the-loop design, and privacy-aware analytics. It establishes the theoretical foundation that underpins the core concepts and technologies utilized in this research.

\textbf{Chapter III: System Design and Architecture.} This chapter outlines the methodology and technical blueprint for the system. It explains the adoption of Design Science Research and presents the system's high-level conceptual architecture, focusing on the five components of the \textbf{Safety Agent Suite}: four specialized agents (STA, TCA, CMA, IA) and the Aika Meta-Agent orchestrator. It details the underlying cloud-native technical architecture, justifying the chosen technology stack, including the use of \textbf{LangGraph} for agent orchestration and a \textbf{FastAPI} backend for the core application logic. It also describes the database structure, user interface design, and integrated security and privacy measures like k-anonymity.

\textbf{Chapter IV: Implementation and Evaluation.} This chapter describes the development and testing of the system prototype. This chapter details the technical environment used for implementation and demonstrates the functional prototype that was built. It then explains the testing process used to evaluate the system's performance against its design requirements. The chapter concludes by presenting the results from these tests and providing an analysis of the findings.

\textbf{Chapter V: Conclusion and Future Work.} This chapter summarizes the study's findings and contributions. This chapter revisits the initial research problems and presents the main conclusions drawn from the research. It concludes by offering recommendations for both the future development of the system and for subsequent research in this area.

% Akhir dari Chapter 1
