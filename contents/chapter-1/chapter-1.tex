\chapter{Introduction}
\label{chap:introduction}

\section{Background}
\label{sec:background}


Higher Education Institutions (HEIs) are facing a critical and growing challenge in supporting student well-being \cite{hill2024studentwellbeing, duraku2024overcoming}. A landmark report highlights the escalating prevalence of mental health and substance use issues among student populations, urging institutions to adopt a more comprehensive support model \cite{scherer2021mentalhealth}. This crisis not only jeopardizes students' academic success and personal development but also places an immense, unsustainable strain on the institutions tasked with supporting them. Recent global surveys indicate that nearly 42\% of university students meet the criteria for at least one mental health disorder, while the average counselor-to-student ratio in higher education remains around 1:1,500, well above recommended levels for effective service delivery \cite{lipson2022healthy, gallagher2023counselor}.

The traditional support model, centered around on-campus counseling services, is fundamentally \textbf{reactive}. It relies on students to self-identify their distress and navigate the process of seeking help. This paradigm faces significant operational challenges, including insufficient staffing, long waiting lists, and an inability to provide immediate, 24/7 support, which ultimately limits access for a large portion of the student body \cite{baik2019universities}. Consequently, a critical gap persists between the need for mental health services and their actual provision, leaving many students without timely support \cite{outay2024multiagent}.

To bridge this gap, a paradigm shift from a reactive to a \textbf{proactive} support model is imperative \cite{outay2024multiagent}. The engine for this evolution is \textbf{Digital Transformation}, a process that leverages technology to fundamentally reshape organizational processes and enhance value delivery within HEIs \cite{omirali2025digitaltrust}. Within this context, Artificial Intelligence (AI) has emerged as a key enabling technology, with systematic reviews confirming its significant potential to analyze complex data, automate processes, and deliver personalized interventions at scale within the higher education landscape \cite{pati2025agentic, karunanayake2025nextgen}.

However, most existing AI applications in university mental health remain limited to passive chatbots or predictive dashboards that, while insightful, depend on human operators to interpret and act upon their outputs, a limitation widely recognized as the \textit{insight-to-action gap} \cite{jorno2018actionableinsight, susnjak2022dashboard}. This thesis argues that overcoming this gap requires a more autonomous paradigm, in which AI systems do not merely predict or inform but can proactively decide and act.

This research therefore moves beyond conventional AI applications by proposing the use of \textbf{Agentic AI}. An intelligent agent is an autonomous system capable of perception, decision-making, and proactive action to achieve specific goals \cite{saleem2025multiagent, wooldridge2009introductionmas}, representing a new frontier in educational technology \cite{salutari2024mas}. We propose that a framework built upon a system of collaborative intelligent agents, a \textbf{Multi-Agent System (MAS)}, can create a truly transformative ecosystem. Such a system would not only serve as a support tool for students but, more importantly, would function as a strategic asset for the institution, enabling data-driven decision-making, automating operational workflows, and facilitating a proactive stance on student well-being. 

This framework is prototyped within the \textbf{UGM-AICare Project}, a collaborative university research initiative focused on developing AI-driven mental health and well-being tools for the Universitas Gadjah Mada (UGM) community. The project serves as the practical testbed for validating the proposed agentic system in a real institutional context.

To clarify the paradigm shift this research proposes, Table~\ref{tab:support_paradigms} presents a systematic comparison of three mental health support models: traditional in-person counseling, reactive AI chatbots, and the proposed proactive multi-agent framework. This comparison reveals that both traditional and chatbot-based approaches share a fundamental limitation, they are \textbf{reactive systems that depend on student-initiated help-seeking behavior}. The proposed framework addresses this limitation through continuous monitoring, automated risk detection, and proactive intervention while maintaining human oversight for safety-critical decisions.

\begin{table}[htbp]
    \centering
    \caption{Comparison of mental health support paradigms: Traditional, chatbot, and proposed proactive multi-agent systems.}
    \label{tab:support_paradigms}
    \small
    \setlength{\tabcolsep}{3pt}
    \begin{tabular}{p{2.3cm}p{3.2cm}p{3.2cm}p{3.8cm}}
        \toprule
        \textbf{Characteristic} & \textbf{Traditional In-Person Counseling} & \textbf{Reactive AI Chatbots} & \textbf{Proposed Multi-Agent Framework (UGM-AICare)} \\
        \midrule
        \textbf{Initiation Model} & Student must self-refer and schedule appointment & Student must open app and initiate conversation & Continuous monitoring with automated outreach capability; system-initiated intervention \\
        \midrule
        \textbf{Availability} & Limited office hours (typically 9am-5pm); multi-week waitlists common & 24/7 availability; instant response & 24/7 availability with proactive intervention triggers; automated escalation protocols \\
        \midrule
        \textbf{Scalability} & Constrained by counselor-to-student ratio (1:1500 average); unsustainable at scale & Scales to unlimited concurrent users & Scales through automated triage and routing; human oversight reserved for critical cases \\
        \midrule
        \textbf{Data Utilization} & Manual case notes; no population-level trend analysis & Individual conversation logs; limited cross-user insights & Population-level analytics with privacy-preserving aggregation; automated intervention routing based on trends \\
        \midrule
        \textbf{Intervention Timing} & \textbf{After crisis escalates} (reactive: student seeks help post-crisis) & \textbf{After student reaches out} (reactive: depends on user initiation) & \textbf{Before crisis peaks} (proactive: automated risk detection triggers early intervention) \\
        \midrule
        \textbf{Administrative Integration} & Manual case management; human-dependent scheduling and follow-up workflows & No administrative integration; standalone conversational interface & Automated case creation, appointment scheduling, resource allocation, and counselor notification \\
        \midrule
        \textbf{Key Limitation} & \textbf{Relies entirely on student help-seeking behavior}; barriers include stigma, lack of awareness, symptom-induced apathy & \textbf{Still requires student to initiate contact}; does not reach students who avoid seeking help & Requires validation through controlled testing before clinical deployment; performance not yet validated on live student populations \\
        \midrule
        \textbf{Human Oversight} & Direct human delivery of all services & Minimal oversight; no clinical escalation path & Human-in-the-loop for all critical decisions; automated triage with mandatory counselor review \\
        \bottomrule
    \end{tabular}
\end{table}

The critical insight from this comparison is that technological advancement alone (moving from in-person to chatbot) does not address the fundamental barrier: \textbf{vulnerable students who need help most are precisely those least likely to initiate contact} \cite{PLACEHOLDER_CITE_help_seeking_barriers, PLACEHOLDER_CITE_mental_health_stigma}. This research hypothesizes that closing this gap requires a paradigm shift from reactive to proactive support, operationalized through autonomous agent-based monitoring and intervention.


%-------------------------------------------------

\section{Problem Formulation}
\label{sec:problem_formulation}

The inefficiency and reactive nature of current university mental health support systems present a complex problem. To move towards a proactive and scalable model, this research addresses the following core challenges:

\begin{enumerate}
    \item The primary challenge is the \textbf{design of a cohesive, safety-oriented agentic AI framework} capable of automating key institutional processes. This requires a shift from a monolithic chatbot to a multi-agent system where specialized agents handle distinct tasks, including real-time crisis detection, personalized coaching, clinical case management, and privacy-preserving analytics.

    \item The technical challenge of \textbf{orchestrating a heterogeneous multi-agent system} in a robust, scalable, and secure cloud-native architecture. This involves managing stateful, long-running interactions and ensuring reliable communication between agents powered by external, non-deterministic LLMs.

    \item The methodological challenge of \textbf{validating the framework's functional capabilities and potential for impact in the absence of a full-scale clinical trial}. This requires developing meaningful, scenario-based testing protocols that can effectively demonstrate the agentic workflows and their advantages over static systems.
\end{enumerate}

To address these challenges, this thesis proposes and details the \textbf{Safety Agent Suite}, a framework comprised of four specialized, collaborative intelligent agents: a \textbf{Safety Triage Agent (STA)}, a \textbf{Therapeutic Coach Agent (TCA)}, a \textbf{Case Management Agent (CMA)}, and an \textbf{Insights Agent (IA)}, coordinated through an \textbf{Aika Meta-Agent} (orchestrator) that provides unified, role-based orchestration and ensures coherent, safety-first interactions across all user roles.

%-------------------------------------------------	

\section{Objectives}
\label{sec:objectives}

The primary objectives of this thesis are:
\begin{enumerate}
    \item To design an agentic AI framework, grounded in the BDI model of rational agency, that systematically bridges the 'insight-to-action' gap in institutional mental health support.
    \item To implement a functional proof-of-concept prototype, the 'Safety Agent Suite,' demonstrating the orchestration of specialized agents (triage, coaching, service desk, insights) and a meta-agent coordinator using LangGraph.
    \item To evaluate the prototype's core agentic workflows through scenario-based testing, validating its capacity for proactive intervention and automated administrative action.
\end{enumerate}

%-------------------------------------------------

\section{Research Questions}
\label{sec:research_questions}

To keep the scope concrete and measurable, this thesis addresses the following research questions (RQs):

\begin{enumerate}
    \item \textbf{RQ1 (Proactive Safety):} Can the agentic framework reliably distinguish between crisis and non-crisis user states to trigger a timely and appropriate safety protocol?
    \item \textbf{RQ2 (Functional Correctness):} Does the multi-agent framework correctly execute its core automated workflows, such as routing users to the appropriate specialized agent and invoking necessary tools?
    \item \textbf{RQ3 (Output Quality \& Privacy):} Can the framework generate outputs (coaching advice, institutional insights) that are both appropriate for their purpose and compliant with privacy-preserving principles?
\end{enumerate}

These questions directly inform the evaluation in Chapter IV through scenario-based tests and transparent metrics (e.g., sensitivity, workflow success rate, rubric scores), with human oversight preserved for safety-critical cases.

%-------------------------------------------------	

\section{Scope and Limitations}
\label{sec:scope_and_limitations}

To ensure the feasibility and focus of this bachelor's thesis, the following boundaries are explicitly established:

\begin{enumerate}
    \item \textbf{Focus on Multi-Agent Architecture Only:} This research is focused exclusively on the \textbf{design, implementation, and evaluation of the multi-agent AI framework itself}, the Safety Agent Suite's BDI-based specialist agents, the Aika Meta-Agent orchestration layer, and their collective behavior in safety-critical conversational scenarios. The full UGM-AICare implementation includes database schema design, user interface components, blockchain token systems, and deployment infrastructure; however, \textbf{these system components are documented as implementation context but are not subjects of formal evaluation in this work}.

    \item \textbf{Proof-of-Concept Evaluation Scope:} The evaluation adopts a \textbf{proof-of-concept validation approach} appropriate for bachelor's-level Design Science Research. The objective is to demonstrate \textbf{technical feasibility} that the Safety Agent Suite can execute core workflows correctly under controlled conditions. Evaluation uses modest sample sizes: 50 crisis scenarios for safety triage (RQ1), 10 conversation flows for orchestration (RQ2), 10 coaching scenarios for response quality (RQ3), and code review with unit tests for privacy validation (RQ4). This approach validates architectural correctness without requiring extensive data collection infrastructure, consistent with DSR artifact evaluation conventions where initial validation focuses on demonstrating capability rather than exhaustive performance characterization.

    \item \textbf{Simulated Data for Privacy and Feasibility:} All testing utilizes \textbf{synthetically generated student mental health crisis scenarios and simulated conversation patterns} created using GPT-4 and Claude 3.5 Sonnet, not real user data. This approach is necessary to protect privacy during development and to enable controlled evaluation without requiring human subjects approval. However, it means that agent performance has not been validated on the specific linguistic diversity, cultural contexts, and edge cases of a live Indonesian student population. Ground truth labels for synthetic scenarios are provided by the primary researcher with peer validation, acknowledging that clinical expert validation remains future work.

    \item \textbf{Single-Rater Assessment with AI Validation:} Response quality evaluation (RQ3) is conducted by the primary researcher using a structured rubric, with GPT-4 performing independent validation on the same responses to provide a reference point for consistency. This pragmatic approach demonstrates the evaluation methodology while acknowledging that inter-rater reliability analysis with multiple clinical experts and formal therapeutic quality assessment using validated instruments (e.g., Cognitive Therapy Scale) remain future work appropriate for clinical validation studies.

    \item \textbf{Privacy-Aware Design Without Formal Proofs:} This research implements k-anonymity enforcement ($k \geq 5$) with code-level verification and unit testing to validate privacy safeguards function as designed. This demonstrates \textbf{privacy-aware agent behavior} and implementation correctness within the prototype context. However, it does not pursue full differential privacy proofs, formal threat modeling using frameworks like LINDDUN, or cryptographic verification—activities appropriate for production security audits but beyond bachelor's thesis scope.

    \item \textbf{Technical Feasibility, Not Clinical Efficacy:} This evaluation demonstrates that the proposed multi-agent architecture is \textit{technically feasible}. The agents can classify crises, orchestrate workflows, generate appropriate responses, and enforce privacy thresholds under controlled conditions. It does \textbf{not} claim to have validated clinical efficacy (long-term mental health outcome improvement), cultural appropriateness for Indonesian students, operational sustainability, or production-readiness for deployment without further testing. Such claims would require ethics approval, multi-rater expert evaluation, field pilots with real users, longitudinal outcome measurement, and cost-benefit analysis, activities beyond bachelor's thesis scope but identified as critical future work in Chapter IV, Section~\ref{sec:discussion}.
\end{enumerate}

\section{Contributions}
\label{sec:contributions}

This thesis contributes a focused blueprint and evidence base for safety‑oriented agentic support:

\begin{enumerate}
    \item \textbf{Safety pipeline specification}. A concrete guideline for triage and escalation: risk cues and scoring, guardrails and redaction steps, decision thresholds, human‑in‑the‑loop invariants, and service targets such as time‑to‑escalation.
    \item \textbf{Agent orchestration design}. A LangGraph view of the Safety Agent Suite—nodes, edges, and typed state schemas—plus the supporting tool‑use protocol (validated schemas, idempotency, retry/backoff) that keeps workflows predictable.
    \item \textbf{Evaluation assets and findings}. Scenario-based tests (synthetic crisis set, adversarial prompts, blinded coaching rubric) and their results, covering safety sensitivity, orchestration reliability, latency, and coaching quality under human oversight.
\end{enumerate}

\section{Thesis Outline}
\label{sec:thesis_outline}

The structure of this thesis is outlined as follows:

\textbf{Chapter I: Introduction.} This chapter elaborates on the background of the study, the justification for the research's significance, the problem formulation to be addressed, and the specific objectives to be achieved. It also defines the scope and limitations of the research, outlines the expected contributions, and presents the overall organizational structure of the thesis report.

\textbf{Chapter II: Literature Review and Theoretical Framework.} This chapter surveys prior work on agentic and conversational AI for mental health, safety-critical triage systems, human-in-the-loop design, and privacy-aware analytics. It establishes the theoretical foundation that underpins the core concepts and technologies utilized in this research.

\textbf{Chapter III: System Design and Architecture.} This chapter outlines the methodology and technical blueprint for the system. It explains the adoption of Design Science Research and presents the system's high-level conceptual architecture, focusing on the five components of the \textbf{Safety Agent Suite}: four specialized agents (STA, TCA, CMA, IA) and the Aika Meta-Agent orchestrator. It details the underlying cloud-native technical architecture, justifying the chosen technology stack, including the use of \textbf{LangGraph} for agent orchestration and a \textbf{FastAPI} backend for the core application logic. It also describes the database structure, user interface design, and integrated security and privacy measures like differential privacy.

\textbf{Chapter IV: Implementation and Evaluation.} This chapter describes the development and testing of the system prototype. This chapter details the technical environment used for implementation and demonstrates the functional prototype that was built. It then explains the testing process used to evaluate the system's performance against its design requirements. The chapter concludes by presenting the results from these tests and providing an analysis of the findings.

\textbf{Chapter V: Conclusion and Future Work.} This chapter summarizes the study's findings and contributions. This chapter revisits the initial research problems and presents the main conclusions drawn from the research. It concludes by offering recommendations for both the future development of the system and for subsequent research in this area.

% Akhir dari Chapter 1
