% Abstract
\noindent
Higher Education Institutions face rising demand for student well-being support while relying on reactive counseling frameworks that often fail to reach students before crises escalate. This thesis proposes and evaluates a proactive, agentic AI framework designed to bridge the critical `insight-to-action' gap by enabling early intervention and data-driven resource management. We introduce the \textit{Safety Agent Suite}, a decoupled multi-agent architecture that distributes clinical and operational responsibilities to specialized agents under human oversight. The system features: (i) \textbf{Aika}, a Meta-Agent orchestrator that provides a unified user interface and performs immediate Tier 1 risk screening; (ii) a \textbf{Safety Triage Agent (STA)} for comprehensive Tier 2 conversational risk analysis; (iii) a \textbf{Therapeutic Coach Agent (TCA)} delivering Cognitive Behavioral Therapy (CBT)-based micro-interventions; (iv) a \textbf{Case Management Agent (CMA)} for operational coordination; and (v) an \textbf{Insights Agent (IA)} for privacy‑preserving resource management analytics. To balance responsiveness with depth, we employ a two-tier risk monitoring architecture that combines immediate screening with deep conversational analysis to enable early intervention. The multi‑agent system is built with LangGraph and includes guardrails for tool use, redaction, and auditability.

\noindent
We implement a functional prototype within the UGM-AICare platform and conduct scenario‑based evaluations focused exclusively on agent architecture performance: triage sensitivity and False Negative Rate (FNR) on synthetic crisis scenarios; orchestration reliability via tool‑call success and state transition behavior; end‑to‑end latency; privacy compliance verification; and coaching quality via CBT adherence rubrics with expert assessment and LLM validation. \textbf{This thesis focuses specifically on the design and evaluation of the multi-agent framework itself}—the BDI-based specialist agents, Aika orchestration layer, and their collective behavior in safety-critical conversational contexts. Database design, user interface components, and deployment infrastructure are documented as implementation context but are not subjects of formal evaluation. Key findings include: (1) the two-tier safety architecture achieves a \textbf{0\% False Negative Rate} through complementary Tier 1 (72\% sensitivity) and Tier 2 (100\% sensitivity) detection; (2) orchestration accuracy of \textbf{64.71\%}, with failures predominantly conservative (over-escalation), indicating need for prompt refinement; and (3) therapeutic response quality of \textbf{4.08/5.0}, exceeding the 3.5 target threshold. These results demonstrate the technical feasibility of proactive safety, functional agent orchestration with identified areas for refinement, and privacy-preserving support, confirming the system's capacity to close the insight-to-action gap under human‑in‑the‑loop supervision. We discuss ethical considerations, privacy by design principles, research limitations, and outline requirements for future clinical field studies with real users.

\noindent\textbf{Keywords}: Multi-Agent Systems; BDI Architecture; Agent Orchestration; Safety Triage; LangGraph; Human‑in‑the‑Loop; Student Well‑being; Scenario-Based Evaluation

