% Abstract
\noindent
Higher Education Institutions face rising demand for student well-being support while operating largely reactive, high-friction service models. This thesis proposes and evaluates a safety‑oriented, multi-agent AI framework that coordinates specialized agents to enable proactive, scalable support under human oversight. The core artifact, the Safety Agent Suite, comprises: (i) an Aika Meta-Agent providing unified orchestration with integrated Tier 1 immediate risk screening, (ii) a Safety Triage Agent for Tier 2 comprehensive conversation-level risk analysis, (iii) a Therapeutic Coach Agent delivering CBT‑based therapeutic micro‑interventions, (iv) a Case Management Agent for clinical case coordination and operational follow‑ups, and (v) an Insights Agent for privacy‑preserving aggregate analytics. The two-tier risk monitoring architecture (Aika's per-message screening + STA's conversation analysis) achieves 45-60\% reduction in LLM API costs while improving clinical accuracy through holistic contextual assessment. The multi‑agent system is built with LangGraph and includes guardrails for tool use, redaction, and auditability.

\noindent
We implement a functional prototype within the UGM-AICare platform and conduct scenario‑based evaluations focused exclusively on agent architecture performance: triage sensitivity/specificity on synthetic crisis scenarios; orchestration reliability via tool‑call success and state transition behavior; end‑to‑end latency; robustness against prompt‑injection; and coaching quality via CBT adherence rubrics with blinded human ratings. \textbf{This thesis focuses specifically on the design and evaluation of the multi-agent framework itself}—the BDI-based specialist agents, Aika orchestration layer, and their collective behavior in safety-critical conversational contexts. Database design, user interface components, and deployment infrastructure are documented as implementation context but are not subjects of formal evaluation. Results demonstrate the feasibility of reliable agent orchestration with bounded latency and controllable failure modes under human‑in‑the‑loop supervision. We discuss ethical considerations, privacy by design principles, research limitations, and outline requirements for future clinical field studies with real users.

\noindent\textbf{Keywords}: Multi-Agent Systems; BDI Architecture; Agent Orchestration; Safety Triage; LangGraph; Human‑in‑the‑Loop; Student Well‑being; Scenario-Based Evaluation

