% Abstract
\noindent
Higher Education Institutions face rising demand for student well-being support while operating largely reactive, high-friction service models. This thesis proposes and prototypes a safety‑oriented, agentic AI framework that coordinates specialized agents to enable proactive, scalable support under human oversight. The core artifact, the Safety Agent Suite, comprises: (i) a Safety Triage Agent for risk screening and escalation, (ii) a Support Coach Agent delivering brief CBT‑informed micro‑interventions, (iii) a lightweight Service Desk Agent for operational follow‑ups, and (iv) an Insights Agent for privacy‑preserving aggregate analytics to inform service improvement. Agents are orchestrated with a graph-based controller and a large language model, with guardrails for tool use, redaction, and auditability.

\noindent
We implement a functional prototype and conduct scenario‑based evaluations focused on agent performance and safety: triage sensitivity/specificity on synthetic crisis prompts and time‑to‑escalation; orchestration reliability via tool‑call success and retry behavior; end‑to‑end latency; robustness against prompt‑injection; and coaching quality via a rubric for CBT adherence and appropriateness with blinded human ratings. For the Insights Agent, we report minimal, aggregate‑level sanity checks (e.g., stable topic counts under privacy thresholds) without individual‑level claims. Results demonstrate the feasibility of reliable agent orchestration with bounded latency and controllable failure modes under human‑in‑the‑loop supervision. We discuss ethical considerations, privacy by design for analytics at aggregate levels, and limitations, and outline requirements for future clinical and field studies.

\noindent\textbf{Keywords}: Agentic AI; Multi‑Agent Systems; Safety Triage; Insights; Human‑in‑the‑Loop; LangGraph; Student Well‑being; Evaluation
